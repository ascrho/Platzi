{"cells":[{"cell_type":"markdown","metadata":{"id":"XXPDOk3zk6CI"},"source":["# ETL de datos de importación de productos"]},{"cell_type":"markdown","metadata":{"id":"Wy1F5LuvlDo-"},"source":["## Instalación de librerías base"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"kvkfu3hli-We","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import Conn_postgresql as connPOSGRE\n","import pandas as pd\n","from sqlalchemy import create_engine, text\n","import uuid"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"DZG-TZxpi-Wh","pycharm":{"name":"#%% md\n"}},"source":["## Extraction: Se crean todos los DF para realziar las operaciones."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8Kg_cWhi-Wj","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#CONSULTA A POSTGRE SQL\n","engine = create_engine('postgresql+psycopg2://postgres:mysecretpass@localhost/postgres') #Ruta para conectarse a SQL desde el sqlalchemy\n","df_trades = pd.read_sql(\"select * from trades\", engine) #Crea un df, con el resultado de la consulta a la BD a traves de la conexion engine (42 seg.)\n","\n","#conn = connPOSGRE.ConnPOSGRESQL() #Tambien se puede usar esta conexion, pero arrojara un warning dado que pandas es compatible con conexiones a traves de sqlalchemy (34 seg.)\n","#df_trades2 = pd.read_sql(\"select * from trades\", engine) #Crea un df, con el resultado de la consulta a la BD a traves de la conexion engine\n","#conn.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Permite leer los primeros 5 registros del df\n","df_trades.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nECq5AcCi-Wk","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#CONSULTA A ARCHIVO JSON\n","\n","#Crea el df_countries, con los registros del json\n","df_countries = pd.read_json('C:/Users/marco/OneDrive/Escritorio/Platzi/Fundamentos de ETL con Python y Pentaho/Notebooks/country_data.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Permite leer los primeros 5 registros del df\n","df_countries.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aw4sjt_ei-Wk","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#CONSULTA A ARCHIVO CSV\n","\n","#Crea el df_codes, con los registros del csv\n","df_codes = pd.read_csv('C:/Users/marco/OneDrive/Escritorio/Platzi/Fundamentos de ETL con Python y Pentaho/Notebooks/hs_codes.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Permite leer los primeros 5 registros del df\n","df_codes.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Crea el df_parents, como una copia con los registros del df df_codes, filtrando solo por los que tengan el valor Level=2. Importante no olvidar los (), para que el copy retorne un df\n","df_parents = df_codes[df_codes['Level']==2].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Permite leer los registros del df\n","df_parents"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"CaNM8Unmi-Wk","pycharm":{"name":"#%% md\n"}},"source":["## Transform"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"2oSQLcOZi-Wl","pycharm":{"name":"#%% md\n"}},"source":["#### Clean codes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXQuUAAfi-Wl","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_codes = df_codes[df_codes['Code_comm'].notnull()] #Elmina los registros donde Code_comm is not null"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Funcion de limpieza\n","#Recibe una cadena\n","#Si el largo del campo code del df df_codes es igual a 11, toma los primeros 5 como el code, y el primero como el parent_code\n","#Si el largo del campo code del df df_codes es distinto de 11, toma los primeros 5 como el code, y los 2 primeros como el parent_code\n","#Luego almacena las descripciones en la variable parent, siempre que Code_comm = parent_code\n","#Finalmente retorna una tupla con los valores code y parent\n","\n","def clean_code(text):\n","    text = str(text) #Convierte el texto recibido en un string\n","    parent_code = None\n","    if len(text) == 11: #Si el lardo del string es igual a 11\n","        code = text[:5] #code sera igual a los 5 primeros digitos del string\n","        parent_code = text[:1] #parent_code sera igual al primer digito del string\n","    else:\n","        code = text[:6] #code sera igual a los 6 primeros digitos del string\n","        parent_code = text[:2] #parent_code sera igual a los 2 primeros digitos del string\n","\n","    #Funcion try\n","    try:\n","        #Se crea la variable parent a partir del df_parents, que retorna una tupla [code,parent] siempre que Code_comm sea igual al parent_code de la funcion clean_code, y retorna solo los valores de la columna Description, como string\n","        parent = df_parents[df_parents['Code_comm'] == parent_code]['Description'].values[0]\n","    except:\n","        parent = None\n","\n","    return(code,parent) #Retorna una tupla con los valores code y parent"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Inserta las columas clean_code y parent_description, dentro del df df_codes\n","#Estas seran el resultado de, aplciar la funcion clean_code, sobre la columna Code, la cual retorna una tupla con los valores (code,parent)\n","    #apply, permite aplicar funciones sobre las columnas\n","    #lambda, sintaxis de escritura para solicitar una acción\n","    #axis, por donde hara el recorrido, el valor 1 indica que lo realizara sobre cada fila, el valor 0 indica que lo hara sobre cada columna\n","    #result_type, para indicar de que manera retornara el resultado, en este caso expand, indica que sera una tupla de 2 valores, que conformaran los valores de las 2 columnas a agregar\n","\n","df_codes[['clean_code','parent_description']] = df_codes.apply(lambda x : clean_code(x['Code']), axis=1, result_type='expand')\n","\n","set(df_codes['Level']) #Obtiene los valores unicos de la columna Level\n","df_codes[df_codes['Level']==2] #Obtiene los registros siempre que Levell sea igual a 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Recrea el df df_codes, filtrando solo los registros donde el clean_code no sea null, y retornando solo los campos 'clean_code','Description','parent_description'\n","df_codes = df_codes[df_codes['clean_code'].notnull()][['clean_code','Description','parent_description']]\n","\n","df_codes['id_code'] = df_codes.index + 1 #Inserta una columna con el valor del propio indice del df mas 1\n","df_codes['clean_code'] = df_codes['clean_code'].astype('int64') #Actuliza el tipo de dato clean_code de str a int64\n","\n","#Reordena las columnas del df df_codes\n","df_codes = df_codes[['id_code','clean_code','Description','parent_description']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_codes"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"fd-QvMWUi-Wn","pycharm":{"name":"#%% md\n"}},"source":["### Clean Countries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvKwSKLai-Wn","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Recrea el df df_countries, filtrando solo los registros donde el clean_code no sea null, y retornando solo los campos 'alpha-3','country','region','sub-region'\n","df_countries = df_countries[df_countries['alpha-3'].notnull()][['alpha-3','country','region','sub-region']]\n","df_countries['id_country'] = df_countries.index + 1 #Inserta una columna con el valor del propio indice del df mas 1\n","\n","#Reordena las columnas del df df_countries\n","df_countries = df_countries[['id_country','alpha-3','country','region','sub-region']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0psKP8Kpi-Wn","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_countries"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"cWScEcGgi-Wn","pycharm":{"name":"#%% md\n"}},"source":["### Merge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajZjpZBPi-Wn","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Crea el df df_trades_clean, haciendo un join de todos los campos del df df_trades left join solo los campos 'clean_code','id_code' del df df_codes, on df_trades.comm_code = df_codes.clean_code\n","df_trades_clean = df_trades.merge(df_codes[['clean_code','id_code']], how='left',left_on='comm_code',right_on='clean_code')\n","\n","#Recrea el df df_trades_clean, haciendo un join de todos los campos del df df_trades_clean left join solo los campos 'alpha-3','id_country' del df df_countries, on df_trades_clean.country_code = df_countries.alpha-3\n","df_trades_clean = df_trades_clean.merge(df_countries[['alpha-3','id_country']], how='left',left_on='country_code',right_on='alpha-3')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5urH1F55i-Wn","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_trades_clean"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"YVNqH6epi-Wo","pycharm":{"name":"#%% md\n"}},"source":["### Clean trades"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"948JzVUSi-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Funcion que permite crear tablas de dimension a partir de un df existente\n","#Recibe un df, en este caso se usaran los valores unicos de una columnas, y el nombre que recibira el campo\n","#Retorna un df con los campos: id_name(Parametro que se pasa a la funcion) y values(Valores entregados en el primer parametro)\n","\n","def create_dimension (data, id_name):\n","    list_keys = []\n","    value = 1\n","    for _ in data:\n","        list_keys.append(value) #Inserta los valores de ID, iniciando en 1\n","        value += 1\n","    \n","    return pd.DataFrame({id_name:list_keys, 'values':data})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2DHcmqsi-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Crea las tablas de dimentsion, a partir de la funcion create_dimension\n","\n","#Dimension para quantity_name\n","df_quantity = create_dimension(df_trades_clean['quantity_name'].unique(),'id_quantity')\n","\n","#Dimension para flow\n","df_flow = create_dimension(df_trades_clean['flow'].unique(),'id_flow')\n","\n","#Dimension para year\n","df_year = create_dimension(df_trades_clean['year'].unique(),'id_year')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-WTbQ7ki-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_quantity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"je5w1xWci-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_flow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtkuIkTgi-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_year"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AB97fTfJi-Wp","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Recrea el df df_trades_clean, haciendo un join de todos los campos del df df_trades_clean left join con todo el df df_quantity, on df_trades_clean.quantity_name = df_quantity.values\n","df_trades_clean = df_trades_clean.merge(df_quantity, how='left', left_on='quantity_name', right_on='values')\n","\n","#Recrea el df df_trades_clean, haciendo un join de todos los campos del df df_trades_clean left join con todo el df df_flow, on df_trades_clean.flow = df_flow.values\n","df_trades_clean = df_trades_clean.merge(df_flow, how='left', left_on='flow', right_on='values')\n","\n","#Recrea el df df_trades_clean, haciendo un join de todos los campos del df df_trades_clean left join con todo el df df_year, on df_trades_clean.year = df_year.values\n","df_trades_clean = df_trades_clean.merge(df_year, how='left', left_on='year', right_on='values')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Inserta el campo id_trades, con el valor index+1\n","df_trades_clean['id_trades'] = df_trades_clean.index + 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Crea el df df_trades_final, a partir del df df_trades_clean, tomando solo las columnas 'id_trades','trade_usd','kg','quantity','id_code','id_country','id_quantity','id_flow','id_year'\n","df_trades_final = df_trades_clean[['id_trades','trade_usd','kg','quantity','id_code','id_country','id_quantity','id_flow','id_year']].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_trades_final"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"tjsSQNuQi-Wp","pycharm":{"name":"#%% md\n"}},"source":["## Load"]},{"cell_type":"code","execution_count":179,"metadata":{},"outputs":[],"source":["#Elimina y re crea las tablas donde se va a almacenar la informacion ya trabajada, usando el script del archivo \"tablas_csv.sql\"\n","engine = create_engine('postgresql+psycopg2://postgres:mysecretpass@localhost/postgres') #Ruta para conectarse a SQL desde el sqlalchemy\n","\n","with engine.connect() as con:\n","    with open('C:\\\\Users\\\\marco\\\\OneDrive\\\\Escritorio\\\\Platzi\\\\Fundamentos de ETL con Python y Pentaho\\\\Notebooks\\\\tablas_csv.sql') as file:\n","        query = text(file.read())\n","        con.execute(query)\n","        con.commit()\n","\n","engine.dispose()"]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[],"source":["#Renombra las columnas para que tengan el mismo nombre que la tabla en la BD\n","\n","df_codes = df_codes.rename(columns={'clean_code':'codes','Description':'description'})\n","df_quantity = df_quantity.rename(columns={'values':'quantity'})\n","df_flow = df_quantity.rename(columns={'id_quantity':'id_flow','quantity':'flow'})\n","df_year = df_quantity.rename(columns={'id_quantity':'id_year','quantity':'year'})"]},{"cell_type":"code","execution_count":183,"metadata":{"id":"Mnyq5Csei-Wp","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Crea los 6 archivos .csv \"trades, countries, codes, quantity, flow, year\" a partir de los respectivos df, en la ruta indicada, excluye la columna con los indices, y el separador sera \"|\"\n","\n","ruta_origen = 'C:/Users/marco/OneDrive/Escritorio/Platzi/Fundamentos de ETL con Python y Pentaho/Archivos/CSV/'\n","df_trades_final.to_csv(ruta_origen+'trades_final.csv',index=False, sep='|')\n","df_countries.to_csv(ruta_origen+'countries.csv',index=False, sep='|')\n","df_codes.to_csv(ruta_origen+'codes.csv',index=False, sep='|')\n","df_quantity.to_csv(ruta_origen+'quantity.csv',index=False, sep='|')\n","df_flow.to_csv(ruta_origen+'flow.csv',index=False, sep='|')\n","df_year.to_csv(ruta_origen+'years.csv',index=False, sep='|')"]},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[],"source":["#Funcion para cargar CSV a la BD, a traves del engine\n","\n","#Recibe la ruta completa donde esta almacenado el CSV\n","def load_file(file_name):\n","\n","    #Extrae el nombre del archivo CSV, debe ser igual al nombre de la tabla en la BD\n","    table_name = file_name.split('\\\\')[len(file_name.split('\\\\'))-1].replace(\".csv\",\"\")\n","\n","    #Abre la ruta del archivo\n","    with open(file_name, 'r') as file:\n","        df = pd.read_csv(file.name, delimiter='|') #Crea un df con el archivo csv\n","        cols = str(list(df.columns))[2:-2].replace(\"-\",\"_\").replace(\"'\",\"\") #Obtiene las columnas a partir del df\n","        conn = create_engine('postgresql+psycopg2://postgres:mysecretpass@localhost/postgres').raw_connection() #Permite usar el metodo \"cursor\" del engine a traves del metodo raw_connection\n","        cursor = conn.cursor() \n","        cmd = f'COPY {table_name}({cols}) FROM STDIN WITH (FORMAT CSV, DELIMITER \"'\"|\"'\", HEADER)'\n","        cursor.copy_expert(cmd, file)\n","        conn.commit()"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["flow\n","C:\\Users\\marco\\OneDrive\\Escritorio\\Platzi\\Fundamentos de ETL con Python y Pentaho\\Notebooks\\CSV\\\n","id_flow, quantity\n"]}],"source":["#Permite conocer a partir de la ruta del CVS, como se obtiene la ruta, el nombre del archivo y los nombre de sus columnas\n","\n","ruta1 = r'C:\\Users\\marco\\OneDrive\\Escritorio\\Platzi\\Fundamentos de ETL con Python y Pentaho\\Notebooks\\CSV\\flow.csv'\n","df = pd.read_csv(ruta1, delimiter='|') #Crea un df con el archivo csv\n","cols = str(list(df.columns))[2:-2].replace(\"-\",\"_\").replace(\"'\",\"\") #Obtiene las columnas a partir del df\n","\n","print(ruta1.split('\\\\')[len(ruta1.split('\\\\'))-1].replace(\".csv\",\"\")) #Obtiene el nombre de un archivo CVS a partir de su ruta completa\n","print(ruta1.replace(ruta1.split('\\\\')[len(ruta1.split('\\\\'))-1],'')) #Extra de la ruta completa del CSV, solo la ruta sin el archivo\n","print(cols)"]},{"cell_type":"code","execution_count":180,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Inicia la carga de CSVs...\n","Carga de trades_final, terminada.\n","Carga de countries, terminada.\n","Carga de codes, terminada.\n","Carga de quantity, terminada.\n","Carga de flow, terminada.\n","Carga de year, terminada.\n"]}],"source":["#Carga los archivos CSV generados a la BD por medio de la funcion load_file()\n","print('Inicia la carga de CSVs...')\n","\n","load_file(r'C:\\Users\\marco\\OneDrive\\Escritorio\\Platzi\\Fundamentos de ETL con Python y Pentaho\\Notebooks\\CSV\\trades_final.csv')\n","print('Carga de trades_final, terminada.')\n","\n","load_file(r'C:\\Users\\marco\\OneDrive\\Escritorio\\Platzi\\Fundamentos de ETL con Python y Pentaho\\Notebooks\\CSV\\countries.csv')\n","print('Carga de countries, terminada.')\n","\n","load_file(r'C:\\Users\\marco\\OneDrive\\Escritorio\\Platzi\\Fundamentos de ETL con Python y Pentaho\\Notebooks\\CSV\\codes.csv')\n","print('Carga de codes, terminada.')\n","\n","load_file(r'C:\\Users\\marco\\OneDrive\\Escritorio\\Platzi\\Fundamentos de ETL con Python y Pentaho\\Notebooks\\CSV\\quantity.csv')\n","print('Carga de quantity, terminada.')\n","\n","load_file(r'C:\\Users\\marco\\OneDrive\\Escritorio\\Platzi\\Fundamentos de ETL con Python y Pentaho\\Notebooks\\CSV\\flow.csv')\n","print('Carga de flow, terminada.')\n","\n","load_file(r'C:\\Users\\marco\\OneDrive\\Escritorio\\Platzi\\Fundamentos de ETL con Python y Pentaho\\Notebooks\\CSV\\years.csv')\n","print('Carga de year, terminada.')"]},{"cell_type":"code","execution_count":181,"metadata":{},"outputs":[],"source":["engine.dispose()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
