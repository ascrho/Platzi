{"cells":[{"cell_type":"markdown","metadata":{"id":"XXPDOk3zk6CI"},"source":["# ETL de datos de importación de productos"]},{"cell_type":"markdown","metadata":{"id":"Wy1F5LuvlDo-"},"source":["## Instalación de librerías base"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"kvkfu3hli-We","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import Conn_postgresql as connPOSGRE\n","import pandas as pd\n","from sqlalchemy import create_engine\n","import uuid"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"DZG-TZxpi-Wh","pycharm":{"name":"#%% md\n"}},"source":["## Extraction: Se crean todos los DF para realziar las operaciones."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8Kg_cWhi-Wj","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#CONSULTA A POSTGRE SQL\n","engine = create_engine('postgresql+psycopg2://postgres:mysecretpass@localhost/postgres') #Ruta para conectarse a SQL desde el sqlalchemy\n","df_trades = pd.read_sql(\"select * from trades\", engine) #Crea un df, con el resultado de la consulta a la BD a traves de la conexion engine (42 seg.)\n","\n","conn = connPOSGRE.ConnPOSGRESQL() #Tambien se puede usar esta conexion, pero arrojara un warning dado que pandas es compatible con conexiones a traves de sqlalchemy (34 seg.)\n","df_trades2 = pd.read_sql(\"select * from trades\", engine) #Crea un df, con el resultado de la consulta a la BD a traves de la conexion engine\n","conn.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Permite leer los primeros 5 registros del df\n","df_trades.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nECq5AcCi-Wk","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#CONSULTA A ARCHIVO JSON\n","\n","#Crea el df_countries, con los registros del json\n","df_countries = pd.read_json('C:/Users/marco/OneDrive/Escritorio/Platzi/Fundamentos de ETL con Python y Pentaho/Notebooks/country_data.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Permite leer los primeros 5 registros del df\n","df_countries.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aw4sjt_ei-Wk","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#CONSULTA A ARCHIVO CSV\n","\n","#Crea el df_codes, con los registros del csv\n","df_codes = pd.read_csv('C:/Users/marco/OneDrive/Escritorio/Platzi/Fundamentos de ETL con Python y Pentaho/Notebooks/hs_codes.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Permite leer los primeros 5 registros del df\n","df_codes.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Crea el df_parents, como una copia con los registros del df df_codes, filtrando solo por los que tengan el valor Level=2. Importante no olvidar los (), para que el copy retorne un df\n","df_parents = df_codes[df_codes['Level']==2].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Permite leer los registros del df\n","df_parents"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"CaNM8Unmi-Wk","pycharm":{"name":"#%% md\n"}},"source":["## Transform"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"2oSQLcOZi-Wl","pycharm":{"name":"#%% md\n"}},"source":["#### Clean codes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXQuUAAfi-Wl","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_codes = df_codes[df_codes['Code_comm'].notnull()] #Elmina los registros donde Code_comm is not null"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Funcion de limpieza\n","#Recibe una cadena\n","#Si el largo del campo code del df df_codes es igual a 11, toma los primeros 5 como el code, y el primero como el parent_code\n","#Si el largo del campo code del df df_codes es distinto de 11, toma los primeros 5 como el code, y los 2 primeros como el parent_code\n","#Luego almacena las descripciones en la variable parent, siempre que Code_comm = parent_code\n","#Finalmente retorna una tupla con los valores code y parent\n","\n","def clean_code(text):\n","    text = str(text) #Convierte el texto recibido en un string\n","    parent_code = None\n","    if len(text) == 11: #Si el lardo del string es igual a 11\n","        code = text[:5] #code sera igual a los 5 primeros digitos del string\n","        parent_code = text[:1] #parent_code sera igual al primer digito del string\n","    else:\n","        code = text[:6] #code sera igual a los 6 primeros digitos del string\n","        parent_code = text[:2] #parent_code sera igual a los 2 primeros digitos del string\n","\n","    #Funcion try\n","    try:\n","        #Se crea la variable parent a partir del df_parents, que retorna una tupla [code,parent] siempre que Code_comm sea igual al parent_code de la funcion clean_code, y retorna solo los valores de la columna Description, como string\n","        parent = df_parents[df_parents['Code_comm'] == parent_code]['Description'].values[0]\n","    except:\n","        parent = None\n","\n","    return(code,parent) #Retorna una tupla con los valores code y parent"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Inserta las columas clean_code y parent_description, dentro del df df_codes\n","#Estas seran el resultado de, aplciar la funcion clean_code, sobre la columna Code, la cual retorna una tupla con los valores (code,parent)\n","    #apply, permite aplicar funciones sobre las columnas\n","    #lambda, sintaxis de escritura para solicitar una acción\n","    #axis, por donde hara el recorrido, el valor 1 indica que lo realizara sobre cada fila, el valor 0 indica que lo hara sobre cada columna\n","    #result_type, para indicar de que manera retornara el resultado, en este caso expand, indica que sera una tupla de 2 valores, que conformaran los valores de las 2 columnas a agregar\n","\n","df_codes[['clean_code','parent_description']] = df_codes.apply(lambda x : clean_code(x['Code']), axis=1, result_type='expand')\n","\n","set(df_codes['Level']) #Obtiene los valores unicos de la columna Level\n","df_codes[df_codes['Level']==2] #Obtiene los registros siempre que Levell sea igual a 2"]},{"cell_type":"code","execution_count":268,"metadata":{},"outputs":[],"source":["#Recrea el df df_codes, filtrando solo los registros donde el clean_code no sea null, y retornando solo los campos 'clean_code','Description','parent_description'\n","df_codes = df_codes[df_codes['clean_code'].notnull()][['clean_code','Description','parent_description']]\n","\n","df_codes['id_code'] = df_codes.index + 1 #Inserta una columna con el valor del propio indice del df mas 1\n","df_codes['clean_code'] = df_codes['clean_code'].astype('int64') #Actuliza el tipo de dato clean_code de str a int64\n","\n","#Reordena las columnas del df df_codes\n","df_codes = df_codes[['id_code','clean_code','Description','parent_description']]"]},{"cell_type":"code","execution_count":269,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_code</th>\n","      <th>clean_code</th>\n","      <th>Description</th>\n","      <th>parent_description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>10011</td>\n","      <td>LIVE ANIMALS; ANIMAL PRODUCTS</td>\n","      <td>LIVE ANIMALS</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>10021</td>\n","      <td>LIVE ANIMALS</td>\n","      <td>LIVE ANIMALS</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>10100</td>\n","      <td>Live horses, asses, mules and hinnies</td>\n","      <td>LIVE ANIMALS</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>10121</td>\n","      <td>Pure-bred breeding horses</td>\n","      <td>LIVE ANIMALS</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>10129</td>\n","      <td>Live horses (excl. pure-bred for breeding)</td>\n","      <td>LIVE ANIMALS</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7432</th>\n","      <td>7433</td>\n","      <td>970200</td>\n","      <td>Original engravings, prints and lithographs</td>\n","      <td>WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES</td>\n","    </tr>\n","    <tr>\n","      <th>7433</th>\n","      <td>7434</td>\n","      <td>970300</td>\n","      <td>Original sculptures and statuary, in any material</td>\n","      <td>WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES</td>\n","    </tr>\n","    <tr>\n","      <th>7434</th>\n","      <td>7435</td>\n","      <td>970400</td>\n","      <td>Postage or revenue stamps, stamp-postmarks, fi...</td>\n","      <td>WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES</td>\n","    </tr>\n","    <tr>\n","      <th>7435</th>\n","      <td>7436</td>\n","      <td>970500</td>\n","      <td>Collections and collector's pieces of zoologic...</td>\n","      <td>WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES</td>\n","    </tr>\n","    <tr>\n","      <th>7436</th>\n","      <td>7437</td>\n","      <td>970600</td>\n","      <td>Antiques of &gt; 100 years old</td>\n","      <td>WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6446 rows × 4 columns</p>\n","</div>"],"text/plain":["      id_code  clean_code                                        Description  \\\n","1           2       10011                      LIVE ANIMALS; ANIMAL PRODUCTS   \n","2           3       10021                                       LIVE ANIMALS   \n","3           4       10100              Live horses, asses, mules and hinnies   \n","5           6       10121                          Pure-bred breeding horses   \n","6           7       10129         Live horses (excl. pure-bred for breeding)   \n","...       ...         ...                                                ...   \n","7432     7433      970200        Original engravings, prints and lithographs   \n","7433     7434      970300  Original sculptures and statuary, in any material   \n","7434     7435      970400  Postage or revenue stamps, stamp-postmarks, fi...   \n","7435     7436      970500  Collections and collector's pieces of zoologic...   \n","7436     7437      970600                        Antiques of > 100 years old   \n","\n","                                 parent_description  \n","1                                      LIVE ANIMALS  \n","2                                      LIVE ANIMALS  \n","3                                      LIVE ANIMALS  \n","5                                      LIVE ANIMALS  \n","6                                      LIVE ANIMALS  \n","...                                             ...  \n","7432  WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES  \n","7433  WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES  \n","7434  WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES  \n","7435  WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES  \n","7436  WORKS OF ART, COLLECTORS' PIECES AND ANTIQUES  \n","\n","[6446 rows x 4 columns]"]},"execution_count":269,"metadata":{},"output_type":"execute_result"}],"source":["df_codes"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"fd-QvMWUi-Wn","pycharm":{"name":"#%% md\n"}},"source":["### Clean Countries"]},{"cell_type":"code","execution_count":266,"metadata":{"id":"qvKwSKLai-Wn","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Recrea el df df_countries, filtrando solo los registros donde el clean_code no sea null, y retornando solo los campos 'alpha-3','country','region','sub-region'\n","df_countries = df_countries[df_countries['alpha-3'].notnull()][['alpha-3','country','region','sub-region']]\n","df_countries['id_country'] = df_countries.index + 1 #Inserta una columna con el valor del propio indice del df mas 1\n","\n","#Reordena las columnas del df df_countries\n","df_countries = df_countries[['id_country','alpha-3','country','region','sub-region']]"]},{"cell_type":"code","execution_count":267,"metadata":{"id":"0psKP8Kpi-Wn","pycharm":{"name":"#%%\n"}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_country</th>\n","      <th>alpha-3</th>\n","      <th>country</th>\n","      <th>region</th>\n","      <th>sub-region</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>AFG</td>\n","      <td>Afghanistan</td>\n","      <td>Asia</td>\n","      <td>Southern Asia</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>ALB</td>\n","      <td>Albania</td>\n","      <td>Europe</td>\n","      <td>Southern Europe</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>DZA</td>\n","      <td>Algeria</td>\n","      <td>Africa</td>\n","      <td>Northern Africa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>AND</td>\n","      <td>Andorra</td>\n","      <td>Europe</td>\n","      <td>Southern Europe</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>AGO</td>\n","      <td>Angola</td>\n","      <td>Africa</td>\n","      <td>Sub-Saharan Africa</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>268</th>\n","      <td>269</td>\n","      <td>UMI</td>\n","      <td>United States Minor Outlying Islands</td>\n","      <td>Oceania</td>\n","      <td>Micronesia</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>270</td>\n","      <td>VGB</td>\n","      <td>Virgin Islands (British)</td>\n","      <td>Americas</td>\n","      <td>Latin America and the Caribbean</td>\n","    </tr>\n","    <tr>\n","      <th>270</th>\n","      <td>271</td>\n","      <td>VIR</td>\n","      <td>Virgin Islands (U.S.)</td>\n","      <td>Americas</td>\n","      <td>Latin America and the Caribbean</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>272</td>\n","      <td>WLF</td>\n","      <td>Wallis and Futuna</td>\n","      <td>Oceania</td>\n","      <td>Polynesia</td>\n","    </tr>\n","    <tr>\n","      <th>272</th>\n","      <td>273</td>\n","      <td>ESH</td>\n","      <td>Western Sahara</td>\n","      <td>Africa</td>\n","      <td>Northern Africa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>249 rows × 5 columns</p>\n","</div>"],"text/plain":["     id_country alpha-3                               country    region  \\\n","0             1     AFG                           Afghanistan      Asia   \n","1             2     ALB                               Albania    Europe   \n","2             3     DZA                               Algeria    Africa   \n","3             4     AND                               Andorra    Europe   \n","4             5     AGO                                Angola    Africa   \n","..          ...     ...                                   ...       ...   \n","268         269     UMI  United States Minor Outlying Islands   Oceania   \n","269         270     VGB              Virgin Islands (British)  Americas   \n","270         271     VIR                 Virgin Islands (U.S.)  Americas   \n","271         272     WLF                     Wallis and Futuna   Oceania   \n","272         273     ESH                        Western Sahara    Africa   \n","\n","                          sub-region  \n","0                      Southern Asia  \n","1                    Southern Europe  \n","2                    Northern Africa  \n","3                    Southern Europe  \n","4                 Sub-Saharan Africa  \n","..                               ...  \n","268                       Micronesia  \n","269  Latin America and the Caribbean  \n","270  Latin America and the Caribbean  \n","271                        Polynesia  \n","272                  Northern Africa  \n","\n","[249 rows x 5 columns]"]},"execution_count":267,"metadata":{},"output_type":"execute_result"}],"source":["df_countries"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"cWScEcGgi-Wn","pycharm":{"name":"#%% md\n"}},"source":["### Merge"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajZjpZBPi-Wn","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Crea el df df_trades_clean, haciendo un join de todos los campos del df df_trades left join solo los campos 'clean_code','id_code' del df df_codes, on df_trades.comm_code = df_codes.clean_code\n","df_trades_clean = df_trades.merge(df_codes[['clean_code','id_code']], how='left',left_on='comm_code',right_on='clean_code')\n","\n","#Recrea el df df_trades_clean, haciendo un join de todos los campos del df df_trades_clean left join solo los campos 'alpha-3','id_country' del df df_countries, on df_trades_clean.country_code = df_countries.alpha-3\n","df_trades_clean = df_trades_clean.merge(df_countries[['alpha-3','id_country']], how='left',left_on='country_code',right_on='alpha-3')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5urH1F55i-Wn","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_trades_clean"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"YVNqH6epi-Wo","pycharm":{"name":"#%% md\n"}},"source":["### Clean trades"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"948JzVUSi-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Funcion que permite crear tablas de dimension a partir de un df existente\n","#Recibe un df, en este caso se usaran los valores unicos de una columnas, y el nombre que recibira el campo\n","#Retorna un df con los campos: id_name(Parametro que se pasa a la funcion) y values(Valores entregados en el primer parametro)\n","\n","def create_dimension (data, id_name):\n","    list_keys = []\n","    value = 1\n","    for _ in data:\n","        list_keys.append(value) #Inserta los valores de ID, iniciando en 1\n","        value += 1\n","    \n","    return pd.DataFrame({id_name:list_keys, 'values':data})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2DHcmqsi-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Crea las tablas de dimentsion, a partir de la funcion create_dimension\n","\n","#Dimension para quantity_name\n","df_quantity = create_dimension(df_trades_clean['quantity_name'].unique(),'id_quantity')\n","\n","#Dimension para flow\n","df_flow = create_dimension(df_trades_clean['flow'].unique(),'id_flow')\n","\n","#Dimension para year\n","df_year = create_dimension(df_trades_clean['year'].unique(),'id_year')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-WTbQ7ki-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_quantity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"je5w1xWci-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_flow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtkuIkTgi-Wo","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["df_year"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AB97fTfJi-Wp","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["#Recrea el df df_trades_clean, haciendo un join de todos los campos del df df_trades_clean left join con todo el df df_quantity, on df_trades_clean.quantity_name = df_quantity.values\n","df_trades_clean = df_trades_clean.merge(df_quantity, how='left', left_on='quantity_name', right_on='values')\n","\n","#Recrea el df df_trades_clean, haciendo un join de todos los campos del df df_trades_clean left join con todo el df df_flow, on df_trades_clean.flow = df_flow.values\n","df_trades_clean = df_trades_clean.merge(df_flow, how='left', left_on='flow', right_on='values')\n","\n","#Recrea el df df_trades_clean, haciendo un join de todos los campos del df df_trades_clean left join con todo el df df_year, on df_trades_clean.year = df_year.values\n","df_trades_clean = df_trades_clean.merge(df_year, how='left', left_on='year', right_on='values')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Inserta el campo id_trades, con el valor index+1\n","df_trades_clean['id_trades'] = df_trades_clean.index + 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Crea el df df_trades_final, a partir del df df_trades_clean, tomando solo las columnas 'id_trades','trade_usd','kg','quantity','id_code','id_country','id_quantity','id_flow','id_year'\n","df_trades_final = df_trades_clean[['id_trades','trade_usd','kg','quantity','id_code','id_country','id_quantity','id_flow','id_year']].copy()"]},{"cell_type":"code","execution_count":264,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_trades</th>\n","      <th>trade_usd</th>\n","      <th>kg</th>\n","      <th>quantity</th>\n","      <th>id_code</th>\n","      <th>id_country</th>\n","      <th>id_quantity</th>\n","      <th>id_flow</th>\n","      <th>id_year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>312258.0</td>\n","      <td>18777.0</td>\n","      <td>18777.0</td>\n","      <td>6934</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>53508.0</td>\n","      <td>4000.0</td>\n","      <td>4000.0</td>\n","      <td>6934</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>53508.0</td>\n","      <td>4000.0</td>\n","      <td>4000.0</td>\n","      <td>6934</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>409683.0</td>\n","      <td>14790.0</td>\n","      <td>14790.0</td>\n","      <td>6935</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>65066.0</td>\n","      <td>1000.0</td>\n","      <td>1000.0</td>\n","      <td>6935</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6216348</th>\n","      <td>6216349</td>\n","      <td>42100.0</td>\n","      <td>2479.0</td>\n","      <td>2479.0</td>\n","      <td>6925</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6216349</th>\n","      <td>6216350</td>\n","      <td>33558.0</td>\n","      <td>339.0</td>\n","      <td>339.0</td>\n","      <td>6928</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6216350</th>\n","      <td>6216351</td>\n","      <td>327946.0</td>\n","      <td>16000.0</td>\n","      <td>16000.0</td>\n","      <td>6929</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6216351</th>\n","      <td>6216352</td>\n","      <td>28378.0</td>\n","      <td>956.0</td>\n","      <td>956.0</td>\n","      <td>6931</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6216352</th>\n","      <td>6216353</td>\n","      <td>2042182.0</td>\n","      <td>553623.0</td>\n","      <td>553623.0</td>\n","      <td>6933</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6216353 rows × 9 columns</p>\n","</div>"],"text/plain":["         id_trades  trade_usd        kg  quantity  id_code  id_country  \\\n","0                1   312258.0   18777.0   18777.0     6934         155   \n","1                2    53508.0    4000.0    4000.0     6934         155   \n","2                3    53508.0    4000.0    4000.0     6934         155   \n","3                4   409683.0   14790.0   14790.0     6935         155   \n","4                5    65066.0    1000.0    1000.0     6935         155   \n","...            ...        ...       ...       ...      ...         ...   \n","6216348    6216349    42100.0    2479.0    2479.0     6925         155   \n","6216349    6216350    33558.0     339.0     339.0     6928         155   \n","6216350    6216351   327946.0   16000.0   16000.0     6929         155   \n","6216351    6216352    28378.0     956.0     956.0     6931         155   \n","6216352    6216353  2042182.0  553623.0  553623.0     6933         155   \n","\n","         id_quantity  id_flow  id_year  \n","0                  1        1        1  \n","1                  1        2        1  \n","2                  1        3        1  \n","3                  1        1        1  \n","4                  1        2        1  \n","...              ...      ...      ...  \n","6216348            1        1        1  \n","6216349            1        1        1  \n","6216350            1        1        1  \n","6216351            1        1        1  \n","6216352            1        1        1  \n","\n","[6216353 rows x 9 columns]"]},"execution_count":264,"metadata":{},"output_type":"execute_result"}],"source":["df_trades_final"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"tjsSQNuQi-Wp","pycharm":{"name":"#%% md\n"}},"source":["## Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mnyq5Csei-Wp","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import os\n","import boto3\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoRjzy7Ji-Wp","pycharm":{"name":"#%%\n"}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
